{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f8de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab70e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format URL, adding appropriate headers\n",
    "def URL_format(url):\n",
    "    http_flag = 0\n",
    "    www_flag = 0\n",
    "    new_url = \"\"\n",
    "    \n",
    "    if \"http\" not in url[:4]:\n",
    "        http_flag = 1\n",
    "    if \"www\" not in url[:11]:\n",
    "        www_flag = 1\n",
    "\n",
    "    if http_flag == 1:\n",
    "        try:\n",
    "            r = requests.get('https://'+ url)\n",
    "            new_url = \"https://\"\n",
    "        except:\n",
    "            new_url = \"http://\"\n",
    "            \n",
    "        if www_flag == 1:\n",
    "            new_url = new_url + \"www.\"\n",
    "            \n",
    "        new_url = new_url+url\n",
    "    else:\n",
    "        if www_flag == 1:\n",
    "            if url[:5] == \"https\":\n",
    "                new_url = url[:8] + \"www.\" + url[8:]\n",
    "            elif url[:4] == \"http\":\n",
    "                new_url = url[:7] + \"www.\" + url[7:]\n",
    "        else:\n",
    "            new_url = url\n",
    "    \n",
    "    return new_url\n",
    "\n",
    "#Length of URL\n",
    "def URL_len(url):\n",
    "    return len(url)\n",
    "\n",
    "#Length of Hostname\n",
    "def hostname_len(url):\n",
    "    #assumes we start with ://www....\n",
    "    matches = re.findall(\"://www.([\\w\\-\\.]+)\", str(url))\n",
    "    result = 0\n",
    "    if (len(matches) >= 1):\n",
    "        result = len(matches[0])\n",
    "    return result\n",
    "\n",
    "#Length of path\n",
    "def path_len(url):\n",
    "    match_len = len(re.findall(\"://www.[\\w\\-\\.]+([\\/\\w+]*)\", str(url)))\n",
    "    if (match_len > 0):\n",
    "        return len(re.findall(\"://www.[\\w\\-\\.]+([\\/\\w+]*)\", str(url))[0])\n",
    "    return match_len\n",
    "\n",
    "#Length of first directory\n",
    "def first_dir_len(url):\n",
    "    match_len = len(re.findall(\"://www.[\\w\\-\\.]+(\\/\\w+)\", str(url)))\n",
    "    if (match_len > 0):\n",
    "        return len(re.findall(\"://www.[\\w\\-\\.]+(\\/\\w+)\", str(url))[0])\n",
    "    return match_len\n",
    "    \n",
    "#Length of top level domain\n",
    "def top_level_len(url):\n",
    "    domains = re.findall(\"://www.([\\w\\-\\.]+)\", str(url))\n",
    "    if len(domains) != 0:\n",
    "        tld = domains[0].split('.')\n",
    "        return len(tld[-1])\n",
    "    return 0\n",
    "\n",
    "#Count of '-'\n",
    "def count_dash(url):\n",
    "    dashes = 0\n",
    "    for char in url:\n",
    "        if char == '-':\n",
    "            dashes += 1     \n",
    "    return dashes\n",
    "\n",
    "#Count of '@'\n",
    "def count_at(url):\n",
    "    at = 0\n",
    "    for char in url:\n",
    "        if char == '@':\n",
    "            at += 1     \n",
    "    return at\n",
    "\n",
    "#Count of '?'\n",
    "def count_q(url):\n",
    "    q = 0\n",
    "    for char in url:\n",
    "        if char == '?':\n",
    "            q += 1     \n",
    "    return q\n",
    "\n",
    "#Count of '%'\n",
    "def count_percent(url):\n",
    "    percent = 0\n",
    "    for char in url:\n",
    "        if char == '%':\n",
    "            percent += 1     \n",
    "    return percent\n",
    "\n",
    "#Count of '.'\n",
    "def count_dot(url):\n",
    "    dot = 0\n",
    "    for char in url:\n",
    "        if char == '.':\n",
    "            dot += 1     \n",
    "    return dot\n",
    "\n",
    "#Count of '='\n",
    "def count_equal(url):\n",
    "    eq = 0\n",
    "    for char in url:\n",
    "        if char == '=':\n",
    "            eq += 1     \n",
    "    return eq\n",
    "\n",
    "#Count of ';'\n",
    "def count_colon(url):\n",
    "    colon = 0\n",
    "    for char in url:\n",
    "        if char == ';':\n",
    "            colon += 1     \n",
    "    return colon\n",
    "\n",
    "#Count of 'www'\n",
    "def count_www(url):\n",
    "    www = 0\n",
    "    www = len(re.findall(\"www\", str(url)))\n",
    "    return www\n",
    "\n",
    "#Count of numbers\n",
    "def count_numbers(url):\n",
    "    numbers = sum(c.isdigit() for c in url)\n",
    "    return numbers\n",
    "\n",
    "#Count of letters\n",
    "def count_letters(url):\n",
    "    letters = sum(c.isalpha() for c in url)\n",
    "    return letters\n",
    "\n",
    "#Count of directories\n",
    "def dir_count(url):\n",
    "    dirs = 0\n",
    "    for char in url:\n",
    "        if char == '/':\n",
    "            dirs = dirs + 1\n",
    "    #assumes that it starts with ://www....\n",
    "    return dirs - 2\n",
    "\n",
    "#Count of single letter directories\n",
    "def single_letter_dir(url):\n",
    "    sldir = 0\n",
    "    sldir = len(re.findall(\"\\/[\\w]\\/\", str(url)))\n",
    "    return sldir\n",
    "                \n",
    "#Count of queries\n",
    "def query_count(url):\n",
    "    count = 0\n",
    "    count = len(re.findall(\"\\?\\w+(&?\\w+)*\", str(url)))\n",
    "    return count\n",
    "\n",
    "#Ratio of uppercase to lowercase letters\n",
    "def ratio_upper_lower(url):\n",
    "    upperSum = 0\n",
    "    lowerSum = 0\n",
    "    for char in url:\n",
    "        if char.isupper():\n",
    "            upperSum = upperSum + 1\n",
    "        if char.islower():\n",
    "            lowerSum = lowerSum + 1\n",
    "    # if url has 0 of one, this will return 0\n",
    "    if lowerSum == 0:\n",
    "        return upperSum\n",
    "    return upperSum / lowerSum\n",
    "\n",
    "#IP vs not\n",
    "def is_ip(url):\n",
    "    if len(re.findall(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", str(url))) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Shortened or not\n",
    "def is_shortened(url):\n",
    "    shortened = { \"bit.ly\", \"tinyurl\", \"goo.gl\", \"ow.ly\", \"t.co\", \n",
    "                 \"tiny.cc\", \"bit.do\", \"shorte.st\", \"cutt.ly\", \"clkim\"}\n",
    "    \n",
    "    if any(shrt in url for shrt in shortened):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#HTTP vs. HTTPS\n",
    "#Returns 1 if HTTPS, 0 if HTTP\n",
    "def is_https(url):\n",
    "    if url[:5] == 'https':\n",
    "        return 1\n",
    "    elif url[:4] == 'http':\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfda811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv data using pandas\n",
    "majestic_million=pd.read_csv('majestic_million.csv')\n",
    "phishtank=pd.read_csv('phistank_verified_online_data.csv')\n",
    "\n",
    "#Only take the first 10,000 values of the majestic million values\n",
    "majestic_million=majestic_million.head(1000)\n",
    "\n",
    "#Rows are store in res[] after being processed\n",
    "res=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://www.google.com\n",
      "1\n",
      "https://www.facebook.com\n",
      "2\n",
      "https://www.youtube.com\n",
      "3\n",
      "https://www.twitter.com\n",
      "4\n",
      "https://www.instagram.com\n",
      "5\n",
      "https://www.linkedin.com\n",
      "6\n",
      "https://www.microsoft.com\n",
      "7\n",
      "https://www.apple.com\n",
      "8\n",
      "https://www.wikipedia.org\n",
      "9\n",
      "https://www.googletagmanager.com\n",
      "10\n",
      "https://www.youtu.be\n",
      "11\n",
      "https://www.en.wikipedia.org\n",
      "12\n",
      "https://www.plus.google.com\n",
      "13\n",
      "https://www.pinterest.com\n",
      "14\n",
      "https://www.play.google.com\n",
      "15\n",
      "https://www.vimeo.com\n",
      "16\n",
      "https://www.maps.google.com\n",
      "17\n",
      "https://www.adobe.com\n",
      "18\n",
      "https://www.goo.gl\n",
      "19\n",
      "https://www.wordpress.com\n",
      "20\n",
      "https://www.bit.ly\n",
      "21\n",
      "https://www.itunes.apple.com\n",
      "22\n",
      "https://www.github.com\n",
      "23\n",
      "https://www.wordpress.org\n",
      "24\n",
      "https://www.blogspot.com\n",
      "25\n",
      "https://www.docs.google.com\n",
      "26\n",
      "https://www.player.vimeo.com\n",
      "27\n",
      "https://www.amazon.com\n",
      "28\n",
      "https://www.mozilla.org\n",
      "29\n",
      "https://www.yahoo.com\n",
      "30\n",
      "https://www.tumblr.com\n",
      "31\n",
      "https://www.drive.google.com\n",
      "32\n",
      "https://www.support.google.com\n",
      "33\n",
      "https://www.apps.apple.com\n",
      "34\n",
      "https://www.flickr.com\n",
      "35\n",
      "https://www.europa.eu\n",
      "36\n",
      "https://www.gravatar.com\n",
      "37\n",
      "https://www.whatsapp.com\n",
      "38\n",
      "https://www.reddit.com\n",
      "39\n",
      "https://www.nytimes.com\n",
      "40\n",
      "https://www.apache.org\n",
      "41\n",
      "https://www.sites.google.com\n",
      "42\n",
      "http://www.amazonaws.com\n",
      "43\n",
      "https://www.nih.gov\n",
      "44\n",
      "https://www.qq.com\n",
      "45\n",
      "https://www.go.microsoft.com\n",
      "46\n",
      "https://www.support.microsoft.com\n",
      "47\n",
      "https://www.soundcloud.com\n",
      "48\n",
      "https://www.w3.org\n",
      "49\n",
      "https://www.t.co\n",
      "50\n",
      "https://www.forbes.com\n",
      "51\n",
      "https://www.medium.com\n",
      "52\n",
      "https://www.github.io\n",
      "53\n",
      "https://www.api.whatsapp.com\n",
      "54\n",
      "https://www.sourceforge.net\n",
      "55\n",
      "https://www.support.apple.com\n",
      "56\n",
      "https://www.theguardian.com\n",
      "57\n",
      "https://www.ec.europa.eu\n",
      "58\n",
      "https://www.cnn.com\n",
      "59\n",
      "https://www.zoom.us\n",
      "60\n",
      "https://www.ncbi.nlm.nih.gov\n",
      "61\n",
      "https://www.archive.org\n",
      "62\n",
      "https://www.dropbox.com\n",
      "63\n",
      "https://www.creativecommons.org\n",
      "64\n",
      "http://www.macromedia.com\n",
      "65\n",
      "https://www.policies.google.com\n",
      "66\n",
      "https://www.baidu.com\n",
      "67\n",
      "https://www.bbc.co.uk\n",
      "68\n",
      "https://www.who.int\n",
      "69\n",
      "http://www.wixsite.com\n",
      "70\n",
      "https://www.forms.gle\n",
      "71\n",
      "https://www.issuu.com\n",
      "72\n",
      "https://www.vk.com\n",
      "73\n",
      "https://www.weebly.com\n",
      "74\n",
      "https://www.spotify.com\n",
      "75\n",
      "https://www.paypal.com\n",
      "76\n",
      "https://www.cloudflare.com\n",
      "77\n",
      "https://www.l.facebook.com\n",
      "78\n",
      "https://www.m.facebook.com\n",
      "79\n",
      "https://www.tools.google.com\n",
      "80\n",
      "https://www.tinyurl.com\n",
      "81\n",
      "https://www.virginmedia.com\n",
      "82\n",
      "https://www.cdc.gov\n",
      "83\n",
      "https://www.get.adobe.com\n",
      "84\n",
      "https://www.bbc.com\n",
      "85\n",
      "httpd.awww.pache.org\n",
      "86\n",
      "http://www.youtube-nocookie.com\n",
      "87\n",
      "https://www.support.mozilla.org\n",
      "88\n",
      "https://www.php.net\n",
      "89\n",
      "https://www.reuters.com\n",
      "90\n",
      "https://www.washingtonpost.com\n",
      "91\n",
      "https://www.accounts.google.com\n",
      "92\n",
      "https://www.developers.google.com\n",
      "93\n",
      "https://www.wsj.com\n",
      "94\n",
      "https://www.opera.com\n",
      "95\n",
      "https://www.bloomberg.com\n",
      "96\n",
      "https://www.open.spotify.com\n",
      "97\n",
      "https://www.web.archive.org\n",
      "98\n",
      "https://www.imdb.com\n",
      "99\n",
      "https://www.oracle.com\n",
      "100\n",
      "https://www.msn.com\n",
      "101\n",
      "https://www.harvard.edu\n",
      "102\n",
      "https://www.sciencedirect.com\n",
      "103\n",
      "https://www.gnu.org\n",
      "104\n",
      "https://www.wp.com\n",
      "105\n",
      "https://www.weibo.com\n",
      "106\n",
      "https://www.wikimedia.org\n",
      "107\n",
      "https://www.mit.edu\n",
      "108\n",
      "https://www.bing.com\n",
      "109\n",
      "https://www.slideshare.net\n",
      "110\n",
      "https://www.businessinsider.com\n",
      "111\n",
      "https://www.ibm.com\n",
      "112\n",
      "https://www.stanford.edu\n",
      "113\n",
      "http://www.list-manage.com\n",
      "114\n",
      "https://www.w.soundcloud.com\n",
      "115\n",
      "https://www.wiley.com\n",
      "116\n",
      "https://www.windows.microsoft.com\n",
      "117\n",
      "https://www.wix.com\n",
      "118\n",
      "https://www.nginx.org\n",
      "119\n",
      "https://www.nature.com\n",
      "120\n",
      "https://www.un.org\n",
      "121\n",
      "https://www.live.com\n",
      "122\n",
      "https://www.office.com\n",
      "123\n",
      "https://www.wa.me\n",
      "124\n",
      "https://www.telegraph.co.uk\n",
      "125\n",
      "https://www.wpa.qq.com\n",
      "126\n",
      "http://www.go.com\n",
      "127\n",
      "https://www.t.me\n",
      "128\n",
      "https://www.cpanel.net\n",
      "129\n",
      "https://www.doi.org\n",
      "130\n",
      "http://www.nasa.gov\n",
      "131\n",
      "https://www.usatoday.com\n",
      "132\n",
      "https://www.time.com\n",
      "133\n",
      "https://www.dailymail.co.uk\n",
      "134\n",
      "https://www.nginx.com\n",
      "135\n",
      "https://www.eventbrite.com\n",
      "136\n",
      "https://www.cpanel.com\n",
      "137\n",
      "https://www.cnet.com\n",
      "138\n",
      "https://www.surveymonkey.com\n",
      "139\n",
      "https://www.huffingtonpost.com\n",
      "140\n",
      "https://www.ted.com\n",
      "141\n",
      "https://www.bitly.com\n",
      "142\n",
      "https://www.validator.w3.org\n",
      "143\n",
      "https://www.myspace.com\n",
      "144\n",
      "https://www.researchgate.net\n",
      "145\n",
      "https://www.cnbc.com\n",
      "146\n",
      "https://www.springer.com\n",
      "147\n",
      "https://www.gov.uk\n",
      "148\n",
      "http://www.bp.blogspot.com\n",
      "149\n",
      "https://www.ebay.com\n",
      "150\n",
      "https://www.npr.org\n",
      "151\n",
      "https://www.wired.com\n",
      "152\n",
      "https://www.chrome.google.com\n",
      "153\n",
      "https://www.mysql.com\n",
      "154\n",
      "https://www.mail.google.com\n",
      "155\n",
      "https://www.blogger.com\n",
      "156\n",
      "https://www.i0.wp.com\n",
      "157\n",
      "https://www.mp.weixin.qq.com\n",
      "158\n",
      "https://www.i1.wp.com\n",
      "159\n",
      "http://www.cloudfront.net\n",
      "160\n",
      "https://www.i2.wp.com\n",
      "161\n",
      "http://www.hp.com\n",
      "162\n",
      "https://www.independent.co.uk\n",
      "163\n",
      "https://www.amzn.to\n",
      "164\n",
      "https://www.aol.com\n",
      "165\n",
      "https://www.techcrunch.com\n",
      "166\n",
      "https://www.imgur.com\n",
      "167\n",
      "http://www.sitemaps.org\n",
      "168\n",
      "https://www.berkeley.edu\n",
      "169\n",
      "https://www.debian.org\n",
      "170\n",
      "https://www.etsy.com\n",
      "171\n",
      "https://www.commons.wikimedia.org\n",
      "172\n",
      "http://www.googleusercontent.com\n",
      "173\n",
      "https://www.arnebrachhold.de\n",
      "174\n",
      "https://www.themeforest.net\n",
      "175\n",
      "https://www.gc.ca\n",
      "176\n",
      "https://www.link.springer.com\n",
      "177\n",
      "https://www.fpdownload.macromedia.com\n",
      "178\n",
      "https://www.hugedomains.com\n",
      "179\n",
      "https://www.sina.com.cn\n",
      "180\n",
      "https://www.addtoany.com\n",
      "181\n",
      "https://www.latimes.com\n",
      "182\n",
      "https://www.behance.net\n",
      "183\n",
      "https://www.dailymotion.com\n",
      "184\n",
      "https://www.outlook.com\n",
      "185\n",
      "https://www.yelp.com\n",
      "186\n",
      "https://www.amazon.co.uk\n",
      "187\n",
      "https://www.ft.com\n",
      "188\n",
      "https://www.loc.gov\n",
      "189\n",
      "https://www.free.fr\n",
      "190\n",
      "https://www.ietf.org\n",
      "191\n",
      "http://www.beian.gov.cn\n",
      "192\n",
      "https://www.youku.com\n",
      "193\n",
      "https://www.nationalgeographic.com\n",
      "194\n",
      "https://www.unsplash.com\n",
      "195\n",
      "https://www.cornell.edu\n",
      "196\n",
      "https://www.s3.amazonaws.com\n",
      "197\n",
      "https://www.theverge.com\n",
      "198\n",
      "https://www.mailchimp.com\n",
      "199\n",
      "https://www.washington.edu\n",
      "200\n",
      "https://www.theatlantic.com\n",
      "201\n",
      "https://www.baike.baidu.com\n",
      "202\n",
      "https://www.statcounter.com\n",
      "203\n",
      "https://www.digg.com\n",
      "204\n",
      "https://www.scribd.com\n",
      "205\n",
      "https://www.jimdo.com\n",
      "206\n",
      "https://www.google.de\n",
      "207\n",
      "https://www.prnewswire.com\n",
      "208\n",
      "https://www.akismet.com\n",
      "209\n",
      "http://www.xinhuanet.com\n",
      "210\n",
      "https://www.kickstarter.com\n",
      "211\n",
      "https://www.cbsnews.com\n",
      "212\n",
      "https://www.1.bp.blogspot.com\n",
      "213\n",
      "https://www.skype.com\n",
      "214\n",
      "https://www.ca.gov\n",
      "215\n",
      "https://www.about.com\n",
      "216\n",
      "https://www.google.co.uk\n",
      "217\n",
      "https://www.goodreads.com\n",
      "218\n",
      "http://www.fda.gov\n",
      "219\n",
      "https://www.taobao.com\n",
      "220\n",
      "https://www.livejournal.com\n",
      "221\n",
      "https://www.fb.com\n",
      "222\n",
      "https://www.samsung.com\n",
      "223\n",
      "https://www.mailchi.mp\n",
      "224\n",
      "https://www.launchpad.net\n",
      "225\n",
      "https://www.squarespace.com\n",
      "226\n",
      "https://www.twitch.tv\n",
      "227\n",
      "https://www.aboutads.info\n",
      "228\n",
      "https://www.tripadvisor.com\n",
      "229\n",
      "https://www.stackoverflow.com\n",
      "230\n",
      "https://www.shopify.com\n",
      "231\n",
      "http://www.sdssytgc.com\n",
      "232\n",
      "https://www.statista.com\n",
      "233\n",
      "https://www.princeton.edu\n",
      "234\n",
      "https://www.sciencemag.org\n",
      "235\n",
      "https://www.typepad.com\n",
      "236\n",
      "https://www.g.page\n",
      "237\n",
      "http://www.163.com\n",
      "238\n",
      "https://www.huffpost.com\n",
      "239\n",
      "https://www.nbcnews.com\n",
      "240\n",
      "https://www.webmd.com\n",
      "241\n",
      "https://www.change.org\n",
      "242\n",
      "https://www.fr.wikipedia.org\n",
      "243\n",
      "https://www.tandfonline.com\n",
      "244\n",
      "https://www.stumbleupon.com\n",
      "245\n",
      "https://www.foxnews.com\n",
      "246\n",
      "https://www.allaboutcookies.org\n",
      "247\n",
      "https://www.economist.com\n",
      "248\n",
      "https://www.oup.com\n",
      "249\n",
      "https://www.eur-lex.europa.eu\n",
      "250\n",
      "https://www.v.qq.com\n",
      "251\n",
      "http://www.godaddy.com\n",
      "252\n",
      "https://www.networkadvertising.org\n",
      "253\n",
      "http://www.unesco.org\n",
      "254\n",
      "https://www.whitehouse.gov\n",
      "255\n",
      "https://www.bandcamp.com\n",
      "256\n",
      "http://www.addthis.com\n",
      "257\n",
      "https://www.marriott.com\n"
     ]
    }
   ],
   "source": [
    "for index,row in majestic_million.iterrows():\n",
    "    #print(row.IDN_Domain)\n",
    "    url = row.IDN_Domain\n",
    "    print(index)\n",
    "    print(url)\n",
    "\n",
    "    url_res = URL_len(url)\n",
    "    hostname_res = hostname_len(url)\n",
    "    path_res = path_len(url)\n",
    "    first_dir_res = first_dir_len(url)\n",
    "    top_level_res = top_level_len(url)\n",
    "    dash_res = count_dash(url)\n",
    "    at_res = count_at(url)\n",
    "    q_res = count_q(url)\n",
    "    percent_res = count_percent(url)\n",
    "    dot_res = count_dot(url)\n",
    "    equal_res = count_equal(url)\n",
    "    colon_res = count_colon(url)\n",
    "    www_res = count_www(url)\n",
    "    numbers_res = count_numbers(url)\n",
    "    letters_res = count_letters(url)\n",
    "    dir_res = dir_count(url)\n",
    "    single_letter_res = single_letter_dir(url) \n",
    "    query_res = query_count(url)\n",
    "    ratio_upper_lower_res = ratio_upper_lower(url)\n",
    "    ip_res = is_ip(url)\n",
    "    shortened_res = is_shortened(url)\n",
    "    http_res = is_https(url)\n",
    "    \n",
    "    res.append([url,url_res,hostname_res ,path_res,first_dir_res,top_level_res,dash_res,at_res,q_res,percent_res,dot_res,equal_res,colon_res,www_res,numbers_res,letters_res,dir_res,single_letter_res,query_res,ratio_upper_lower_res,ip_res,shortened_res,http_res])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa93b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in phishtank.iterrows():\n",
    "    #print(\"original: \" + row.url)\n",
    "    url = URL_format(row.url)\n",
    "    #print(\"formatted: \" + url)\n",
    "    \n",
    "    url_res = URL_len(url)\n",
    "    hostname_res = hostname_len(url)\n",
    "    path_res = path_len(url)\n",
    "    first_dir_res = first_dir_len(url)\n",
    "    top_level_res = top_level_len(url)\n",
    "    dash_res = count_dash(url)\n",
    "    at_res = count_at(url)\n",
    "    q_res = count_q(url)\n",
    "    percent_res = count_percent(url)\n",
    "    dot_res = count_dot(url)\n",
    "    equal_res = count_equal(url)\n",
    "    colon_res = count_colon(url)\n",
    "    www_res = count_www(url)\n",
    "    numbers_res = count_numbers(url)\n",
    "    letters_res = count_letters(url)\n",
    "    dir_res = dir_count(url)\n",
    "    single_letter_res = single_letter_dir(url) \n",
    "    query_res = query_count(url)\n",
    "    ratio_upper_lower_res = ratio_upper_lower(url)\n",
    "    ip_res = is_ip(url)\n",
    "    shortened_res = is_shortened(url)\n",
    "    http_res = is_https(url)\n",
    "    \n",
    "    res.append([url,url_res,hostname_res ,path_res,first_dir_res,top_level_res,dash_res,at_res,q_res,percent_res,dot_res,equal_res,colon_res,www_res,numbers_res,letters_res,dir_res,single_letter_res,query_res,ratio_upper_lower_res,ip_res,shortened_res,http_res])\n",
    "\n",
    "result_column_names = ['url','url_res','hostname_res','path_res','first_dir_res','top_level_res','dash_res','at_res','q_res','percent_res','dot_res','equal_res','colon_res','www_res','numbers_res','letters_res','dir_res','single_letter_res','query_res','ratio_upper_lower_res','ip_res','shortened_res','http_res']\n",
    "\n",
    "result = pd.DataFrame(res,columns=result_column_names)\n",
    "result.to_csv('out.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71773578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
